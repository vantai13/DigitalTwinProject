import threading
from sqlite3.dbapi2 import Timestamp
from flask import request
from flask_socketio import emit
from app.extensions import digital_twin, data_lock # Import kho hÃ ng chung
from app.utils.logger import get_logger
from app.services.influx_service import influx_service
import queue
import time

logger = get_logger()


# --- 1. KHá»I Táº O HÃ€NG Äá»¢I (QUEUE) ---
# HÃ ng Ä‘á»£i nÃ y Ä‘Ã³ng vai trÃ² "bá»™ Ä‘á»‡m", giÃºp Mininet gá»­i bao nhiÃªu cÅ©ng Ä‘Æ°á»£c,
# Backend sáº½ xá»­ lÃ½ tá»« tá»« mÃ  khÃ´ng bá»‹ treo.

MAX_QUEUE_SIZE = 100  # Chá»‰ cho phÃ©p tá»‘i Ä‘a 100 items trong queue
telemetry_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)

# --- 2. WORKER THREAD (NgÆ°á»i tiÃªu dÃ¹ng) ---
def db_worker():
    """
    HÃ m nÃ y cháº¡y vÄ©nh viá»…n trong 1 thread riÃªng.
    NÃ³ liÃªn tá»¥c láº¥y dá»¯ liá»‡u tá»« queue vÃ  ghi vÃ o InfluxDB.
    """
    logger.info(">>> InfluxDB Worker Ä‘Ã£ khá»Ÿi Ä‘á»™ng vÃ  Ä‘ang chá» dá»¯ liá»‡u...")
    consecutive_errors = 0  # Äáº¿m sá»‘ lá»—i liÃªn tiáº¿p
    while True:
        # Láº¥y dá»¯ liá»‡u tá»« hÃ ng Ä‘á»£i (sáº½ block/Ä‘á»©ng chá» táº¡i Ä‘Ã¢y náº¿u hÃ ng Ä‘á»£i rá»—ng)
        data = telemetry_queue.get()
        
        if data is None: # TÃ­n hiá»‡u dá»«ng (náº¿u cáº§n táº¯t server Ãªm Ä‘áº¹p)
            break
        
        # [Má»šI] Log kÃ­ch thÆ°á»›c queue má»—i 10 láº§n ghi
        current_size = telemetry_queue.qsize()
        if current_size > 50:  # Cáº£nh bÃ¡o khi queue > 50% capacity
            logger.warning(f"âš ï¸ Queue Ä‘ang Ä‘áº§y {current_size}/{MAX_QUEUE_SIZE} items!")
            
        try:
            # Ghi vÃ o DB (TÃ¡c vá»¥ tá»‘n thá»i gian IO)
            influx_service.write_telemetry_batch(data)
            consecutive_errors = 0  # Reset Ä‘áº¿m lá»—i khi ghi thÃ nh cÃ´ng

        except Exception as e:
            logger.error(f"Lá»—i ghi InfluxDB background: {e}")
            # Náº¿u lá»—i liÃªn tiáº¿p > 10 láº§n â†’ InfluxDB cÃ³ thá»ƒ Ä‘Ã£ cháº¿t
            if consecutive_errors >= 10:
                logger.critical("ğŸ”¥ InfluxDB cÃ³ thá»ƒ Ä‘Ã£ ngá»«ng hoáº¡t Ä‘á»™ng! Táº¡m ngÆ°ng ghi 10s...")
                time.sleep(10)  # Ngá»§ 10s Ä‘á»ƒ InfluxDB cÃ³ cÆ¡ há»™i há»“i phá»¥c
                consecutive_errors = 0  # Reset
        finally:
            # ÄÃ¡nh dáº¥u lÃ  Ä‘Ã£ xá»­ lÃ½ xong item nÃ y
            telemetry_queue.task_done()

# --- 3. KHá»I Äá»˜NG WORKER ---
# Chá»‰ cháº¡y 1 láº§n duy nháº¥t khi file nÃ y Ä‘Æ°á»£c import
# daemon=True nghÄ©a lÃ  thread nÃ y sáº½ tá»± cháº¿t khi chÆ°Æ¡ng trÃ¬nh chÃ­nh táº¯t
worker_thread = threading.Thread(target=db_worker, daemon=True)
worker_thread.start()

def register_socket_events(socketio):
    """
    HÃ m nÃ y sáº½ Ä‘Æ°á»£c gá»i táº¡i Factory Ä‘á»ƒ Ä‘Äƒng kÃ½ cÃ¡c sá»± kiá»‡n WebSocket
    """

    @socketio.on('connect')
    def handle_connect():
        """Xá»­ lÃ½ khi client káº¿t ná»‘i"""
        logger.info(f"Client connected: {request.sid}")
        
        # Gá»­i tráº¡ng thÃ¡i ban Ä‘áº§u cho client má»›i
        snapshot = digital_twin.get_network_snapshot()
        emit('initial_state', snapshot)

    @socketio.on('disconnect')
    def handle_disconnect():
        """Xá»­ lÃ½ khi client ngáº¯t káº¿t ná»‘i"""
        logger.info(f"Client disconnected: {request.sid}")

    @socketio.on('mininet_telemetry')
    def handle_mininet_telemetry(data):
        # --- A. Äáº©y data vÃ o queue (vá»›i timeout) ---
        try:
            # Chá»‰ chá» 0.1 giÃ¢y, náº¿u queue Ä‘áº§y thÃ¬ drop data
            telemetry_queue.put(data, block=True, timeout=0.1)
        except queue.Full:
            # Queue Ä‘áº§y â†’ KhÃ´ng ghi Ä‘Æ°á»£c vÃ o DB â†’ Log cáº£nh bÃ¡o
            logger.warning("âš ï¸ QUEUE Äáº¦Y! ÄÃ£ bá» qua 1 batch dá»¯ liá»‡u Ä‘á»ƒ trÃ¡nh trÃ n RAM")
            # KhÃ´ng crash, tiáº¿p tá»¥c xá»­ lÃ½ bÃ¬nh thÆ°á»ng
        
        with data_lock:
            batch_timestamp = data.get('timestamp')
            
            # --- B. Cáº­p nháº­t Digital Twin (tá»« raw data) ---
            for h_data in data.get('hosts', []):
                host = digital_twin.get_host(h_data['name'])
                if host:
                    was_offline = (host.status == 'offline')
                    host.set_status('up')
                    host.update_resource_metrics(h_data['cpu'], h_data['mem'], timestamp=batch_timestamp)
                    
                    if was_offline:
                        socketio.emit('host_updated', host.to_json())
            
            for l_data in data.get('links', []):
                parts = l_data['id'].split('-')
                if len(parts) == 2:
                    link = digital_twin.get_link(parts[0], parts[1])
                    if link:
                        if link.status in ['down', 'offline', 'unknown']:
                            link.set_status('up')
                        link.update_performance_metrics(l_data['bw'], 0, timestamp=batch_timestamp)
            
            for s_data in data.get('switches', []):
                if isinstance(s_data, str):
                    s_name = s_data
                    s_ports = {}
                else:
                    s_name = s_data.get('name')
                    s_ports = s_data.get('ports', {})
                
                switch = digital_twin.get_switch(s_name)
                if switch:
                    switch.heartbeat(timestamp=batch_timestamp)
                    if s_ports:
                        switch.update_port_stats(s_ports, timestamp=batch_timestamp)
            
            for item in data.get('latency', []):
                pair_id = item.get('pair')
                latency_val = item.get('latency')
                loss_val = item.get('loss', 0.0)
                jitter_val = item.get('jitter', 0.0)
                
                if pair_id:
                    parts = pair_id.split('-')
                    if len(parts) == 2:
                        src, dst = parts[0], parts[1]
                        digital_twin.update_path_metrics(src, dst, latency_val, loss_val, jitter_val)
            
            # --- C. Táº¡o SNAPSHOT Má»šI tá»« Digital Twin ---
            # ÄÃ¢y lÃ  cÃ¡ch CHUáº¨N NHáº¤T: Táº¡o representation má»›i tá»« state hiá»‡n táº¡i
            frontend_data = {
                'timestamp': batch_timestamp,
                'hosts': [
                    {
                        'name': h_data['name'],
                        'cpu': h_data['cpu'],
                        'mem': h_data['mem'],
                        'status': digital_twin.get_host(h_data['name']).status
                            if digital_twin.get_host(h_data['name']) else 'unknown'
                    }
                    for h_data in data.get('hosts', [])
                ],
                'links': [
                    {
                        'id': l_data['id'],
                        'bw': l_data['bw'],
                        'status': digital_twin.get_link(
                            l_data['id'].split('-')[0],
                            l_data['id'].split('-')[1]
                        ).status if len(l_data['id'].split('-')) == 2
                            and digital_twin.get_link(
                                l_data['id'].split('-')[0],
                                l_data['id'].split('-')[1]
                            ) else 'unknown'
                    }
                    for l_data in data.get('links', [])
                ],
                'switches': data.get('switches', []),  # Giá»¯ nguyÃªn
                'latency': data.get('latency', [])     # Giá»¯ nguyÃªn
            }
        
        # --- D. Emit snapshot má»›i ---
        socketio.emit('network_batch_update', frontend_data)
        
        logger.info(f"ÄÃ£ nháº­n telemetry tá»« Mininet: {len(frontend_data['hosts'])} hosts")